# Amazon Reviews Sentiment Analysis

## Descripci√≥n del Problema

* **Contexto**: El an√°lisis de sentimiento en rese√±as de Amazon busca extraer insights autom√°ticamente sobre la opini√≥n de los clientes hacia productos, marcas o servicios. Esto ayuda a:
Medir la satisfacci√≥n del cliente.
Identificar problemas recurrentes.
Comparar productos competidores.
Optimizar decisiones de negocio.

* **Relevancia**: Dependiendo quien tuviera la necesidad de resoverlo, puede responder a preguntas como:
Porque bajaron nuestras ventas o valoraciones? o "Queremos lanzar un neuvo producto pero no sabemos que pide el mercado", si se tratara de un vendedor. "Hay miles de resenas, como se si el producto es bueno? de tratarse de un comprador. El foco en este caso estara en el uso de plataformas de Amazoon para detectar rese√±as falsas o manipuladas.

* **Objetivos**: Se espera evitar p√©rdidas de tiempo al no tener que leer manualmente miles de rese√±as, evitar sesgos humanos que un analista podria tener y detectar crisis de reputacion antes de que afecten las ventas.

## Proceso de Procesamiento de Datos

Detalla los pasos seguidos para preparar y procesar los datos:

1.  **Recopilaci√≥n de Datos**: el dataset fue recolectado por McAuley Lab en 2023 (https://amazon-reviews-2023.github.io/ ) y la categoria elegida para muestreo fue All_beauty
2.  **Limpieza de Datos**: Se utilizaron las t√©cnicas de: eliminaci√≥n de valores nulos (NaN) dropna() para eliminar filas con valores faltantes; eliminacion de columnas innecesarias (images, entre otras irrelevantes para el an√°lisis); eliminaci√≥n de duplicados con drop_duplicates() para eliminar filas repetidas y se cre√≥ una copia del DF original df_reviews_clean antes de modificar los datos, preservando el original para evitar p√©rdidas accidentales.
3.  **Transformaci√≥n de Datos**: Las operaciones realizadas para preparar los datos para el an√°lisis fueron: Concatenaci√≥n de columnas; Normalizaci√≥n del texto eliminando distinciones entre may√∫sculas/min√∫sculas; Eliminaci√≥n de stopwords, para remover palabras irrelevantes; Tokenizaci√≥n, es decir dividir el texto en unidades como palabras; Clasificaci√≥n de sentimientos, etiquetando rese√±as como positivo, neutral o negativo seg√∫n la columna 'rating'; finalmente se export√≥ el dataframe procesado en un archivo .csv.
4.  **An√°lisis Exploratorio de Datos (EDA)**: luego del an√°lisis inicial de la estructura, se realizaron visualizaciones de la distribuci√≥n de la columna 'ratings' con gr√°ficos de barras para verificar si hay desbalance de categor√≠as, as√≠ como tambi√©n la frecuencia de las compras verificadas 'verified_purchase'

## ü§ñ Modelos Probados y Resultados

Se probaron distintos modelos de clasificaci√≥n supervisada para predecir la puntuaci√≥n de rese√±as en la categor√≠a `All_beauty` del dataset de Amazon. A continuaci√≥n se detallan los modelos evaluados, las m√©tricas empleadas y los resultados obtenidos:

---

### üî∏ Modelo 1: Na√Øve Bayes (Multinomial)

- **Descripci√≥n**: Modelo probabil√≠stico basado en la aplicaci√≥n del teorema de Bayes con independencia entre caracter√≠sticas. Se aplic√≥ una versi√≥n optimizada sobre los datos vectorizados con TF-IDF.
- **M√©tricas de Evaluaci√≥n**: Accuracy, F1-score Macro y Weighted.
- **Resultados**:
  - Accuracy: **61%**
  - F1-Score Macro: **0.43**
  - F1-Score Weighted: **0.61**
  - Tiempo de ejecuci√≥n: ‚ö° **Muy r√°pido**
  - Observaciones:
    - Buen rendimiento en clase 5.
    - Bajo desempe√±o en clases 1, 2, 3 y 4.
    - Promedio macro bajo por mal desempe√±o en clases minoritarias.

---

### üî∏ Modelo 2: Regresi√≥n Log√≠stica (con GridSearchCV)

- **Descripci√≥n**: Clasificador lineal optimizado mediante b√∫squeda de hiperpar√°metros con validaci√≥n cruzada.
- **M√©tricas de Evaluaci√≥n**: Accuracy, F1-score Macro y Weighted.
- **Resultados**:
  - Accuracy: **67%**
  - F1-Score Macro: **0.44**
  - F1-Score Weighted: **0.62**
  - Tiempo de ejecuci√≥n: ‚è±Ô∏è **Medio**
  - Observaciones:
    - Excelente desempe√±o en clase 5.
    - Dificultades en clases 2, 3 y 4 (bajo recall).
    - Mejor balance general comparado con Na√Øve Bayes.

---

### üî∏ Modelo 3: SVM (Support Vector Machine)

- **Descripci√≥n**: Clasificador de m√°rgenes m√°ximos con kernel lineal, optimizado con b√∫squeda de hiperpar√°metros.
- **M√©tricas de Evaluaci√≥n**: Accuracy, F1-score Macro y Weighted.
- **Resultados**:
  - Accuracy: **65%**
  - F1-Score Macro: **0.42**
  - F1-Score Weighted: **0.60**
  - Tiempo de ejecuci√≥n: üêå **Lento**
  - Observaciones:
    - Alto recall en clase 5.
    - Dificultades similares a Regresi√≥n Log√≠stica en clases intermedias.
    - Mejor balance entre precisi√≥n y recall que Gradient Boosting.

---

### üî∏ Modelo 4: Gradient Boosting

- **Descripci√≥n**: Ensemble basado en √°rboles secuenciales, entrenados para corregir errores de los anteriores.
- **M√©tricas de Evaluaci√≥n**: Accuracy, F1-score Macro y Weighted.
- **Resultados**:
  - Accuracy: **65%**
  - F1-Score Macro: **0.37**
  - F1-Score Weighted: **0.58**
  - Tiempo de ejecuci√≥n: ‚è±Ô∏è **Medio**
  - Observaciones:
    - No detecta la clase 2 (recall = 0%).
    - Confusi√≥n frecuente entre clase 3 y 5.
    - Overfitting en ciertas clases.
    - Recomendado ajustar `min_samples_leaf` y utilizar `class_weight='balanced'`.

---

### üî∏ Modelo 5: XGBoost (Optimizado)

- **Descripci√≥n**: Algoritmo de boosting con regularizaci√≥n y control avanzado del sobreajuste.
- **M√©tricas de Evaluaci√≥n**: Accuracy, F1-score Macro y Weighted.
- **Resultados**:
  - Accuracy: **56%**
  - F1-Score Macro: **0.19**
  - F1-Score Weighted: **0.46**
  - Tiempo de ejecuci√≥n: ‚è±Ô∏è **Medio**
  - Observaciones:
    - P√©simo rendimiento en clases 1 a 4.
    - Alto recall en clase 5 (>90%), indicando sesgo hacia la clase mayoritaria.
    - Posible overfitting; se sugiere reducir `max_depth` y ajustar `scale_pos_weight`.

---

### üìä Comparaci√≥n de Modelos

| Modelo                  | Accuracy | F1 Macro | F1 Weighted | Velocidad | Notas Principales |
|-------------------------|----------|----------|-------------|-----------|-------------------|
| Na√Øve Bayes             | 0.61     | 0.43     | 0.61        | ‚ö° R√°pido  | R√°pido pero d√©bil con clases minoritarias |
| Regresi√≥n Log√≠stica     | 0.67     | 0.44     | 0.62        | ‚è±Ô∏è Medio  | Mejor rendimiento general |
| SVM                     | 0.65     | 0.42     | 0.60        | üêå Lento   | Buen balance, pero costoso |
| Gradient Boosting       | 0.65     | 0.37     | 0.58        | ‚è±Ô∏è Medio  | Problemas con clase 2 |
| XGBoost                 | 0.56     | 0.19     | 0.46        | ‚è±Ô∏è Medio  | Overfitting severo |

---

### üèÜ Modelo Seleccionado: **Regresi√≥n Log√≠stica**

Debido a su buen equilibrio entre precisi√≥n general, rendimiento aceptable en clases minoritarias, y velocidad razonable de entrenamiento, se selecciona **Regresi√≥n Log√≠stica** como el mejor modelo para esta tarea. Se recomienda seguir trabajando en mejorar su recall en clases 2, 3 y 4 con t√©cnicas de rebalanceo o embeddings m√°s ricos sem√°nticamente.

## Conclusiones y Aplicaciones Pr√°cticas

### üîπ Conclusiones Principales

1. **Regresi√≥n Log√≠stica optimizada fue el mejor modelo**: Tras realizar ajustes de hiperpar√°metros con GridSearchCV, la regresi√≥n log√≠stica mostr√≥ un rendimiento s√≥lido, destacando en precisi√≥n general y desempe√±o equilibrado entre clases. Esto sugiere que este modelo es eficaz para capturar patrones en los datos textuales de rese√±as, especialmente en la categor√≠a `All_beauty`.

2. **Desempe√±o por clase**: El modelo tuvo un excelente rendimiento para identificar rese√±as con puntuaciones extremas, como las de 5 estrellas (`f1-score = 0.79`) y aceptable en las de 1 estrella. Sin embargo, presenta limitaciones para clasificar correctamente las opiniones intermedias (2, 3 y 4 estrellas), reflejo de un desbalance en el dataset y la ambig√ºedad natural de rese√±as neutrales.

3. **Importancia del preprocesamiento**: Las t√©cnicas de limpieza, tokenizaci√≥n, eliminaci√≥n de stopwords y vectorizaci√≥n TF-IDF fueron fundamentales para transformar texto en datos √∫tiles para el modelo. Estas etapas marcaron la diferencia en la calidad de predicci√≥n.

4. **Dataset desequilibrado**: El an√°lisis exploratorio evidenci√≥ un claro predominio de rese√±as positivas (mayormente de 5 estrellas), lo que afect√≥ la capacidad de los modelos para clasificar correctamente opiniones negativas o neutras. Esto debe tenerse en cuenta para futuras optimizaciones.

---

### üéØ Aplicaciones Pr√°cticas

1. **Filtrado autom√°tico de rese√±as**: Este sistema puede implementarse en plataformas de e-commerce para clasificar de forma autom√°tica miles de rese√±as, ahorrando tiempo a analistas y usuarios que desean entender r√°pidamente la opini√≥n general sobre un producto.

2. **Detecci√≥n temprana de crisis de reputaci√≥n**: Al identificar aumentos en rese√±as negativas o cambios en la distribuci√≥n de puntuaciones, el modelo puede ser una herramienta clave para alertar sobre problemas de calidad, log√≠stica o atenci√≥n al cliente antes de que impacten significativamente las ventas.

3. **Apoyo a decisiones comerciales**: Vendedores pueden usar este an√°lisis para evaluar qu√© atributos valoran m√°s los consumidores, detectar puntos d√©biles, y adaptar sus productos o estrategias de marketing en consecuencia.

4. **Evaluaci√≥n de rese√±as falsas o manipuladas** *(futuro trabajo)*: A futuro, se podr√≠a incorporar un modelo que identifique patrones at√≠picos en rese√±as muy positivas o negativas, ayudando a Amazon a detectar comportamientos sospechosos y mejorar la confianza en la plataforma.

---

### üöÄ Trabajo Futuro

- **Rebalanceo del dataset** con t√©cnicas como *undersampling*, *oversampling* o *class weighting* para mejorar la clasificaci√≥n en clases minoritarias.
- **Entrenamiento con embeddings** tipo Word2Vec, GloVe o modelos BERT para capturar mejor la sem√°ntica del lenguaje.
- **Ampliar la muestra de rese√±as** a otras categor√≠as para validar la generalizaci√≥n del modelo.
- **Integraci√≥n con herramientas de visualizaci√≥n interactiva** para monitoreo en tiempo real de la percepci√≥n del cliente.



## Instrucciones de Uso

Orden de ejecuci√≥n de los notebooks:
Raw Data ‚Üí EDA ‚Üí Preprocesamiento ‚Üí Modelado ‚Üí Evaluaci√≥n ‚Üí Visualizaci√≥n  

Requisitos: pip install -r requirements.txt

# Librer√≠as Utilizadas en el Proyecto

```python
import os
import re
import warnings
import zipfile
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from bootcampviztools import pinta_distribucion_categoricas
from nltk.corpus import stopwords
import nltk
import json
import random

import pandas as pd
import nltk
from nltk.corpus import stopwords
import re
import os
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
import datetime
import pickle
import os
from sklearn.preprocessing import LabelEncoder

from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import loguniform
import numpy as np
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import xgboost as xgb
from sklearn.utils.class_weight import compute_sample_weight

from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import make_scorer
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns


## Vicky Sequeira