{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8859d0-3e9c-4288-be9d-e28e97e2fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer, f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import loguniform\n",
    "import random\n",
    "\n",
    "# Configuracion\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635419e9-cc4a-449c-906c-8b7a1c9e38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "input_file = r\"C:\\Users\\Vicky\\Desktop\\All_Beauty.jsonl\"\n",
    "output_file = r\"C:\\Users\\Vicky\\Documents\\ML_Amazon_Reviews_Sentiment_Analysis\\data_sample\\raw/dataset_sample_final.jsonl\"\n",
    "sample_fraction = 0.01\n",
    "random_seed = 42\n",
    "\n",
    "# Contar líneas totales y extraer muestra\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "sample_size = max(1, int(total_lines * sample_fraction))\n",
    "selected_lines = sorted(random.sample(range(total_lines), sample_size))\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f_in, open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for i, line in enumerate(f_in):\n",
    "        if i in selected_lines:\n",
    "            f_out.write(line)\n",
    "\n",
    "print(f\"Muestra guardada en {output_file}, tamaño: {sample_size} filas\")\n",
    "\n",
    "# Cargar el JSONL en un DataFrame\n",
    "df_sample = pd.read_json(output_file, lines=True)\n",
    "print(f\"DataFrame creado con {len(df_sample)} filas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5e188b-7a45-40c7-b827-9a347015c8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vicky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vicky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Limpieza y preprocesamiento\n",
    "df_reviews_clean = df_sample.copy().dropna().drop(columns=['images', 'asin', 'parent_asin', 'user_id', 'timestamp']).drop_duplicates()\n",
    "df_reviews_clean['text'] = df_reviews_clean['text'].apply(str) + ' ' + df_reviews_clean['title'].apply(str)\n",
    "df_reviews_clean['text'] = df_reviews_clean['text'].str.lower()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    texto_limpio = re.sub(r'[^a-zA-ZáéíóúüñÁÉÍÓÚÜÑ\\s]', '', texto)\n",
    "    palabras = texto_limpio.split()\n",
    "    palabras_filtradas = [palabra for palabra in palabras if palabra not in stop_words]\n",
    "    return ' '.join(palabras_filtradas)\n",
    "\n",
    "df_reviews_clean['text_limpio'] = df_reviews_clean['text'].apply(limpiar_texto)\n",
    "df_reviews_clean = df_reviews_clean.drop(columns=['text'])\n",
    "\n",
    "# Clasificación del sentimiento\n",
    "df_reviews_clean['sentimiento'] = pd.cut(df_reviews_clean['rating'], bins=[0, 2, 3, 5], labels=['negativo', 'neutral', 'positivo'], right=True)\n",
    "\n",
    "nltk.download('punkt')\n",
    "df_reviews_clean['tokens'] = df_reviews_clean['text_limpio'].apply(lambda x: word_tokenize(str(x).lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fef1373-0048-4532-adb9-7328cfe77c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de datos\n",
    "train_df, test_df = train_test_split(df_reviews_clean, test_size=0.2, random_state=42, stratify=df_reviews_clean['sentimiento'])\n",
    "\n",
    "# Vectorización TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10_000)\n",
    "X_train_tfidf = vectorizer.fit_transform(train_df['text_limpio']).astype('float32')\n",
    "X_test_tfidf = vectorizer.transform(test_df['text_limpio'])\n",
    "y_train = train_df['rating']\n",
    "y_test = test_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edf932d5-da8e-4464-8644-9e7a593d9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "# Ruta de guardado de modelos\n",
    "model_path = r'C:\\Users\\Vicky\\Documents\\ML_Amazon_Reviews_Sentiment_Analysis\\models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5912c2-e95f-4924-9526-071039f0dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión Logística optimizada con Random Search\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "param_dist_lr = {\n",
    "    'C': loguniform(1e-5, 100),\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    lr_model, param_distributions=param_dist_lr, n_iter=100, cv=5, scoring='f1_macro', n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search_lr.fit(X_train_tfidf, y_train)\n",
    "best_lr_model = random_search_lr.best_estimator_\n",
    "y_pred_lr = best_lr_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913ef37-cfdd-4df4-93e1-9b9182fa0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de resultados\n",
    "print(\"Mejores parámetros encontrados:\", random_search_lr.best_params_)\n",
    "print(\"Regresión Logística Optimizado - Precisión en Test:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce0b00-5350-4df1-bc5f-f1e3d9d483aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo optimizado\n",
    "model_components_lr = {\n",
    "    'model': best_lr_model,\n",
    "    'random_search': random_search_lr,\n",
    "    'vectorizer': vectorizer,\n",
    "    'label_encoder': le,\n",
    "    'metadata': {\n",
    "        'model_type': 'Optimized Logistic Regression (RandomizedSearchCV)',\n",
    "        'best_parameters': random_search_lr.best_params_,\n",
    "        'best_score': random_search_lr.best_score_,\n",
    "        'test_accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "        'classification_report': classification_report(y_test, y_pred_lr, output_dict=True),\n",
    "        'training_date': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'features': f\"{X_train_tfidf.shape[1]} features TF-IDF\",\n",
    "        'classes': list(le.classes_),\n",
    "        'cv_results': random_search_lr.cv_results_\n",
    "    }\n",
    "}\n",
    "\n",
    "filename_lr = f\"optimized_logistic_regression_random_final{datetime.datetime.now().strftime('%Y%m%d')}.pkl\"\n",
    "full_path_lr = os.path.join(model_path, filename_lr)\n",
    "\n",
    "with open(full_path_lr, 'wb') as file_lr:\n",
    "    pickle.dump(model_components_lr, file_lr)\n",
    "\n",
    "print(f\"✅ Modelo de Regresión Logística optimizado guardado exitosamente en:\\n{full_path_lr}\")\n",
    "print(f\"\\n Mejores parámetros: {random_search_lr.best_params_}\")\n",
    "print(f\" Mejor score (CV): {random_search_lr.best_score_:.4f}\")\n",
    "print(f\" Accuracy (test): {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Guardar modelo optimizado\n",
    "model_components_lr = {\n",
    "    'model': best_lr_model,\n",
    "    'random_search': random_search_lr,\n",
    "    'vectorizer': vectorizer,\n",
    "    'label_encoder': le,\n",
    "    'metadata': {\n",
    "        'model_type': 'Optimized Logistic Regression (RandomizedSearchCV)',\n",
    "        'best_parameters': random_search_lr.best_params_,\n",
    "        'best_score': random_search_lr.best_score_,\n",
    "        'test_accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "        'classification_report': classification_report(y_test, y_pred_lr, output_dict=True),\n",
    "        'training_date': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'features': f\"{X_train_tfidf.shape[1]} features TF-IDF\",\n",
    "        'classes': list(le.classes_),\n",
    "        'cv_results': random_search_lr.cv_results_\n",
    "    }\n",
    "}\n",
    "\n",
    "filename_lr = f\"optimized_logistic_regression_random_final{datetime.datetime.now().strftime('%Y%m%d')}.pkl\"\n",
    "full_path_lr = os.path.join(model_path, filename_lr)\n",
    "\n",
    "with open(full_path_lr, 'wb') as file_lr:\n",
    "    pickle.dump(model_components_lr, file_lr)\n",
    "\n",
    "print(f\"✅ Modelo de Regresión Logística optimizado guardado exitosamente en:\\n{full_path_lr}\")\n",
    "print(f\"\\n Mejores parámetros: {random_search_lr.best_params_}\")\n",
    "print(f\" Mejor score (CV): {random_search_lr.best_score_:.4f}\")\n",
    "print(f\" Accuracy (test): {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b1f64-f38d-433d-a9d2-22b218b772d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b4963-7230-4f09-8dd2-607c78965a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
